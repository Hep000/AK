{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a391d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "941b265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt','r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "76c8c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c832a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a6644f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    \n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c307dfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8f3346ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "958af71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5a357ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "# W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "C = torch.randn((27, 2), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ef51f3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674, -0.2373],\n",
       "        [-0.0274, -1.1008],\n",
       "        [ 0.2859, -0.0296],\n",
       "        [-1.5471,  0.6049],\n",
       "        [ 0.0791,  0.9046],\n",
       "        [-0.4713,  0.7868]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[:6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7f5ca0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "315bf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2510e2aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we would like to do something like this\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# but emb is the wrong shape (3D)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "# we would like to do something like this\n",
    "emb @ W1 + b1\n",
    "# but emb is the wrong shape (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f838f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want emb to be 32 by 6, the six being 2 by 3 first layer neurons\n",
    "torch.cat([emb[:,0,:], emb[:,1,:], emb[:,2,:]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f0d87143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to cope with any block_size\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ce5a29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more efficiently, as all torch tensors are stored as one-dimensional\n",
    "# emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fd7c0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xDim0 = X.shape[0]\n",
    "h = torch.zeros((xDim0, 100))\n",
    "for i in range(xDim0):\n",
    "    h[i] = emb.view(-1, 6)[i,:] @ W1 + b1\n",
    "#     print(h[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3834fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros((xDim0, 100))\n",
    "for i in range(xDim0):\n",
    "    h[i] = torch.tanh(emb.view(-1, 6)[i,:] @ W1 + b1)\n",
    "#     print(h[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8ecc9e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9348,  1.0000,  0.9258,  ...,  0.9786, -0.1926,  0.9515],\n",
       "        [ 0.2797,  0.9997,  0.7675,  ...,  0.9929,  0.9992,  0.9981],\n",
       "        [-0.9960,  1.0000, -0.8694,  ..., -0.5159, -1.0000, -0.0069],\n",
       "        ...,\n",
       "        [-0.9996,  1.0000, -0.9273,  ..., -0.9999, -0.9974, -0.9970],\n",
       "        [-0.9043,  1.0000,  0.9868,  ..., -0.7859, -0.4819,  0.9981],\n",
       "        [-0.9048,  1.0000,  0.9553,  ...,  0.9866,  1.0000,  0.9907]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(h.shape, h.dtype)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "88f4f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 27]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7139e+00,  1.7004e+00, -5.2536e-01,  ...,  2.2673e-01,\n",
       "          5.7200e-01,  1.2515e+00],\n",
       "        [ 3.9931e-01,  5.8364e-01, -1.8971e+00,  ..., -6.0466e-01,\n",
       "          9.6749e-01, -4.2308e-01],\n",
       "        [-2.5798e-01, -3.0600e-01, -6.5714e-01,  ..., -2.0904e+00,\n",
       "         -2.6559e-01,  1.1214e+00],\n",
       "        ...,\n",
       "        [-9.5891e-01, -4.5719e-04, -2.0679e-01,  ...,  2.1099e+00,\n",
       "          1.3437e-01,  2.0550e+00],\n",
       "        [-1.6093e+00, -6.5691e-02, -2.3609e+00,  ..., -2.4089e-01,\n",
       "         -2.8725e-01,  4.5899e-02],\n",
       "        [-1.2685e+00, -1.3525e+00, -1.8254e-01,  ..., -2.0127e+00,\n",
       "          1.6496e-02, -1.2098e+00]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = torch.randn((100,27))\n",
    "b2 = torch.randn(27)\n",
    "print(W2.shape, W2.dtype)\n",
    "W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "07b16fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h[:,:29] @ W2[:29,:]\n",
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "33af4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.6305e+00,  1.4939e+01,  1.2592e+01,  8.6687e+00, -1.5139e+01,\n",
       "          3.2233e+00,  7.3641e+00, -7.0430e+00, -5.1357e+00,  2.2856e-02,\n",
       "          2.0298e+00,  9.3355e+00, -8.6624e-01,  6.0250e+00, -9.1530e+00,\n",
       "          8.2638e-01, -3.4893e-01, -1.7576e-01, -8.5076e+00, -3.7636e+00,\n",
       "         -2.3550e+00,  1.5538e+01,  8.6370e+00,  2.4770e+00, -4.3730e+00,\n",
       "         -7.8310e-01,  3.4189e+00],\n",
       "        [-1.0677e+01,  9.7100e+00,  2.9911e+00,  3.4321e+00, -7.5804e+00,\n",
       "          3.9931e+00,  7.9634e-01,  3.1430e+00, -7.0838e-01,  1.6692e+00,\n",
       "         -7.3368e+00,  1.1808e+01,  5.5312e+00,  2.7846e+00, -1.2023e+01,\n",
       "          7.3979e+00, -1.5661e+00, -7.3063e+00, -1.0520e+01,  1.0278e-01,\n",
       "         -2.3276e+00,  1.0422e+01,  3.3022e+00,  4.4635e+00, -1.2461e+01,\n",
       "         -6.3743e+00, -3.6290e+00],\n",
       "        [ 3.8093e+00,  8.2363e+00,  1.3480e+01,  1.2749e+01, -3.3486e+00,\n",
       "         -4.9482e+00,  1.2121e+01, -1.0926e+01, -8.3533e+00,  4.6336e-01,\n",
       "          1.3925e+00,  9.9100e+00,  3.7529e+00,  4.8016e+00, -5.1038e+00,\n",
       "          3.0865e+00, -1.7024e+00,  3.4811e+00,  2.6008e+00, -1.7704e+00,\n",
       "         -3.7237e+00,  1.4551e+01, -7.2813e-01, -5.3157e+00,  6.8184e+00,\n",
       "          1.0851e+01,  4.5899e+00],\n",
       "        [-3.2142e+00,  9.5573e+00,  2.0567e+01,  9.3179e+00, -1.3666e+01,\n",
       "         -5.2485e+00,  5.0414e+00,  1.0267e+00, -1.2540e+01, -6.0320e+00,\n",
       "          3.0505e+00,  5.9305e+00, -7.3780e+00,  7.6952e+00, -2.5727e+00,\n",
       "          2.6015e+00,  8.5043e-01, -1.0973e+00, -1.0768e+01, -8.1676e+00,\n",
       "         -1.8105e+00,  5.2265e+00,  4.4099e-01, -1.2448e+01, -7.1087e+00,\n",
       "          7.7673e+00,  8.7396e+00],\n",
       "        [-1.0752e+01,  1.0825e+01,  9.3734e+00,  1.3181e+00, -1.9100e+01,\n",
       "          6.2468e-01,  4.5484e+00, -6.9751e+00, -4.5863e+00,  9.0831e+00,\n",
       "          8.2732e+00,  3.8374e+00, -2.6959e+00,  5.4862e+00, -6.6322e+00,\n",
       "          4.6541e+00,  5.9895e+00,  3.5224e+00, -1.3745e+01, -2.6918e+00,\n",
       "         -5.8947e-01,  1.9824e+01,  1.4165e+00,  6.5323e+00, -1.3058e+00,\n",
       "          2.4222e+00,  6.8871e+00],\n",
       "        [-9.6305e+00,  1.4939e+01,  1.2592e+01,  8.6687e+00, -1.5139e+01,\n",
       "          3.2233e+00,  7.3641e+00, -7.0430e+00, -5.1357e+00,  2.2856e-02,\n",
       "          2.0298e+00,  9.3355e+00, -8.6624e-01,  6.0250e+00, -9.1530e+00,\n",
       "          8.2638e-01, -3.4893e-01, -1.7576e-01, -8.5076e+00, -3.7636e+00,\n",
       "         -2.3550e+00,  1.5538e+01,  8.6370e+00,  2.4770e+00, -4.3730e+00,\n",
       "         -7.8310e-01,  3.4189e+00],\n",
       "        [-9.4061e+00,  8.2777e+00,  6.7112e-01, -5.6796e-01, -4.5802e+00,\n",
       "          4.5391e+00, -1.6769e+00,  2.7426e+00, -8.3342e-01,  4.8615e+00,\n",
       "         -6.3092e+00,  1.0279e+01,  5.2621e+00,  3.5948e+00, -1.0620e+01,\n",
       "          8.7504e+00, -5.5355e-01, -7.7591e+00, -1.1476e+01,  1.2025e+00,\n",
       "         -4.9697e-02,  1.0031e+01,  1.8210e+00,  7.1516e+00, -1.0035e+01,\n",
       "         -5.6367e+00, -4.2785e+00],\n",
       "        [ 2.3706e+00,  7.2404e-02,  3.4293e-01,  1.2268e+01, -5.6693e-01,\n",
       "          9.7459e+00,  7.9758e+00,  6.6198e+00,  7.9353e-01, -1.4031e+00,\n",
       "         -1.4182e+01,  1.8018e+01,  8.7764e+00, -7.1880e+00, -9.1205e+00,\n",
       "          3.4970e+00, -1.1898e+00, -4.3540e+00,  2.8635e+00,  1.6755e+00,\n",
       "          4.6190e+00,  2.6150e+00,  6.8615e+00, -1.4392e+00, -5.3024e+00,\n",
       "         -1.0457e+01,  8.2806e+00],\n",
       "        [ 3.6245e+00, -3.1067e+00,  9.0222e-01, -3.4764e+00,  1.1270e+01,\n",
       "         -4.3338e+00,  2.4713e+00, -1.7498e+01,  6.6608e+00,  5.0486e+00,\n",
       "          7.8974e-01,  2.9508e+00, -6.5664e+00,  4.1201e+00, -2.6171e-01,\n",
       "          4.5264e+00, -7.2363e+00,  7.1626e+00,  1.3810e+01, -6.0305e+00,\n",
       "         -8.8448e+00, -3.2906e+00,  1.1120e+01, -1.3130e+01, -7.5225e+00,\n",
       "          1.3007e+01, -4.3598e-01],\n",
       "        [-9.4006e+00, -3.6151e-01,  7.1938e+00, -3.0760e+00, -1.3699e+01,\n",
       "          4.7026e-01,  2.6480e+00, -1.4462e+01, -6.7403e+00,  3.6949e+00,\n",
       "          5.4891e+00, -2.2904e-01, -7.3497e+00,  5.2602e+00,  5.7319e+00,\n",
       "          1.0339e-01, -2.5375e+00,  2.2941e+00, -3.1575e+00, -7.1787e+00,\n",
       "          3.8161e+00, -9.5021e+00,  6.3166e+00,  2.1979e-01, -1.3451e+00,\n",
       "          7.9645e+00, -8.7761e+00],\n",
       "        [-1.1937e+01,  9.5698e+00,  2.3594e+01,  1.2302e+01, -1.1415e+01,\n",
       "         -3.3956e+00,  1.0203e+01, -8.8015e+00, -2.2990e+00, -3.5268e+00,\n",
       "         -1.7029e+00,  1.1717e+01,  3.6878e+00,  4.2240e+00, -9.5032e+00,\n",
       "         -4.1548e+00,  2.7045e-01, -7.5888e+00, -7.2394e+00, -1.8775e+00,\n",
       "          3.8159e+00,  1.0275e+01, -7.4444e+00, -1.0539e+00,  2.0898e-01,\n",
       "          4.1144e+00,  6.4761e+00],\n",
       "        [-1.1268e+01,  6.5310e+00,  1.9494e+01, -4.3670e-01, -1.5712e+01,\n",
       "          2.5925e+00,  3.2198e+00, -1.2416e+01, -6.2615e+00,  2.4810e+00,\n",
       "          1.3324e+01,  7.2121e+00, -1.6914e+00,  8.2540e+00, -6.8145e+00,\n",
       "          3.1146e+00, -1.1061e+01, -5.3349e+00, -1.3220e+01, -9.1899e-01,\n",
       "          3.1885e+00,  7.9535e+00, -9.9787e+00, -3.2343e+00, -1.6238e+00,\n",
       "          4.8642e+00,  1.0984e+01],\n",
       "        [-9.6305e+00,  1.4939e+01,  1.2592e+01,  8.6687e+00, -1.5139e+01,\n",
       "          3.2233e+00,  7.3641e+00, -7.0430e+00, -5.1357e+00,  2.2856e-02,\n",
       "          2.0298e+00,  9.3355e+00, -8.6624e-01,  6.0250e+00, -9.1530e+00,\n",
       "          8.2638e-01, -3.4893e-01, -1.7576e-01, -8.5076e+00, -3.7636e+00,\n",
       "         -2.3550e+00,  1.5538e+01,  8.6370e+00,  2.4770e+00, -4.3730e+00,\n",
       "         -7.8310e-01,  3.4189e+00],\n",
       "        [-1.1856e+01,  1.1381e+01,  8.2371e+00,  2.4874e+00, -1.8024e+01,\n",
       "         -1.4199e+00,  4.2321e+00, -1.1956e+01, -3.8425e+00,  6.5392e+00,\n",
       "          1.0829e+01,  6.6786e+00, -3.0902e+00,  5.7402e+00, -6.9219e+00,\n",
       "          3.6882e+00,  1.7662e+00,  5.3024e+00, -9.3712e+00, -1.6408e+00,\n",
       "         -3.6072e-01,  1.9367e+01,  8.1501e+00,  5.5057e+00, -6.0383e+00,\n",
       "          1.9903e+00,  4.8084e+00],\n",
       "        [-1.5818e+01,  1.1251e+01,  1.3488e+01,  1.0722e+01, -1.6225e+01,\n",
       "          1.3056e+00,  3.3644e+00, -1.3160e+01,  2.9938e-01, -2.1062e+00,\n",
       "         -2.1033e+00,  7.9736e+00,  1.6147e+00,  3.2700e+00, -1.1517e+01,\n",
       "          7.5595e-01,  4.1651e+00, -2.4960e+00, -2.5000e+00, -2.1344e+00,\n",
       "          3.6967e+00,  6.8792e+00,  3.1430e+00,  6.0847e+00,  1.2007e+00,\n",
       "          1.2610e+00, -2.3790e+00],\n",
       "        [-1.2919e+01,  4.3875e+00,  2.2800e+01,  5.7851e+00, -1.2996e+01,\n",
       "          2.3968e-02,  5.2605e+00, -1.1031e+01, -6.0767e+00, -1.8045e+00,\n",
       "          5.4600e+00,  5.7990e+00,  6.5354e-01,  6.5052e+00, -7.1817e+00,\n",
       "         -2.9147e+00, -8.0417e+00, -5.9155e+00, -1.2793e+01, -2.9013e+00,\n",
       "          2.0329e+00,  3.2630e+00, -1.3486e+01, -1.9713e+00,  2.5393e+00,\n",
       "          8.1883e+00,  7.4638e+00],\n",
       "        [-9.6305e+00,  1.4939e+01,  1.2592e+01,  8.6687e+00, -1.5139e+01,\n",
       "          3.2233e+00,  7.3641e+00, -7.0430e+00, -5.1357e+00,  2.2856e-02,\n",
       "          2.0298e+00,  9.3355e+00, -8.6624e-01,  6.0250e+00, -9.1530e+00,\n",
       "          8.2638e-01, -3.4893e-01, -1.7576e-01, -8.5076e+00, -3.7636e+00,\n",
       "         -2.3550e+00,  1.5538e+01,  8.6370e+00,  2.4770e+00, -4.3730e+00,\n",
       "         -7.8310e-01,  3.4189e+00],\n",
       "        [-1.3337e+01,  1.5737e+01,  1.0951e+01,  3.8665e+00, -1.8754e+01,\n",
       "         -1.9702e+00,  6.6062e+00, -9.4131e+00, -4.9300e+00,  3.9426e+00,\n",
       "          6.7460e+00,  1.0533e+01, -2.6270e+00,  6.7774e+00, -8.5495e+00,\n",
       "          8.2961e-01,  3.5438e-01,  6.8281e+00, -8.9421e+00, -3.8328e+00,\n",
       "         -3.8946e+00,  1.8907e+01,  8.7792e+00,  5.3540e+00, -6.5264e+00,\n",
       "          1.5500e+00,  6.7471e+00],\n",
       "        [-1.4351e+01,  1.3508e+01,  1.3220e+01,  8.4920e+00, -1.7720e+01,\n",
       "          1.0014e+00,  4.6229e+00, -1.1625e+01, -1.9595e+00,  2.1937e-01,\n",
       "          1.5729e+00,  9.8056e+00,  3.6877e-01,  1.5340e+00, -1.0157e+01,\n",
       "          1.0203e+00,  3.3854e+00, -3.1282e+00, -6.5753e+00, -2.1217e+00,\n",
       "          2.1177e+00,  1.2172e+01,  5.3540e+00,  6.3098e+00, -1.6929e+00,\n",
       "          1.0624e-01,  2.2617e+00],\n",
       "        [-1.4734e+01,  1.0176e+01,  2.0931e+01,  7.9522e+00, -1.6003e+01,\n",
       "         -1.1054e+00,  7.0221e+00, -1.4065e+01, -3.7413e+00,  1.1247e-02,\n",
       "          3.5243e+00,  1.0927e+01,  1.9107e+00,  5.8704e+00, -9.9730e+00,\n",
       "         -1.3322e+00, -3.9200e+00, -3.4873e+00, -9.2188e+00, -1.7442e+00,\n",
       "          3.7082e+00,  8.2126e+00, -6.0025e+00,  2.6339e+00, -6.6902e-01,\n",
       "          4.7626e+00,  6.5580e+00],\n",
       "        [-6.9151e+00,  5.3375e-01,  2.4494e+01,  5.4996e+00, -5.2446e+00,\n",
       "          3.6070e+00,  4.0786e+00, -1.0750e-02, -3.9215e+00, -3.6075e+00,\n",
       "          7.8413e-01,  7.7899e+00,  1.6078e+00,  1.9211e+00, -7.4016e+00,\n",
       "         -2.0282e+00, -4.5963e+00, -1.2026e+01, -6.4633e+00, -5.3584e+00,\n",
       "          6.7290e+00,  8.8942e+00, -7.3109e+00, -2.8168e+00,  7.2697e-01,\n",
       "          3.2767e+00,  2.4240e+00],\n",
       "        [-4.8562e+00,  2.1813e-01,  9.6655e+00,  6.2744e+00,  2.3420e+00,\n",
       "          4.7795e+00,  1.6975e+00, -3.4401e+00,  2.7484e-01,  1.7682e+00,\n",
       "          2.8504e+00,  8.7172e+00,  4.5586e+00, -2.5763e+00, -1.1650e+01,\n",
       "          1.4602e+00, -8.4633e+00, -5.7027e+00, -3.2785e+00, -3.0455e+00,\n",
       "         -4.5544e-03,  1.2273e+01, -7.3085e+00, -2.6077e+00, -6.1498e+00,\n",
       "         -3.9855e+00, -2.2827e+00],\n",
       "        [ 2.9168e+00, -9.1995e-01,  4.8067e+00,  1.0153e+01,  7.3229e+00,\n",
       "          8.8382e+00,  1.4713e+01,  4.1297e+00,  4.9148e+00, -2.0616e+00,\n",
       "         -1.6126e+01,  1.5556e+01,  9.6678e+00, -9.8890e+00, -3.1597e+00,\n",
       "          4.1846e+00, -7.3156e+00, -5.8107e+00,  3.8149e+00,  6.7804e+00,\n",
       "          5.0607e+00,  5.1882e+00,  3.3834e+00, -7.9910e+00, -5.6013e+00,\n",
       "         -1.2105e+01,  7.3818e+00],\n",
       "        [ 5.1889e+00, -7.0219e+00,  2.1316e+00, -4.1767e-01,  1.7588e+01,\n",
       "         -1.7139e+00,  8.6156e+00,  2.5030e+00,  7.8240e+00, -2.8290e+00,\n",
       "         -9.7274e+00,  7.3205e+00,  1.3654e+01, -3.6330e+00,  3.1247e+00,\n",
       "          4.4662e+00, -7.7670e+00,  9.0915e+00,  1.2679e+01,  4.6109e+00,\n",
       "          3.3001e+00, -2.4552e-01,  9.7722e+00, -1.0336e+01, -1.5763e+01,\n",
       "         -7.6989e+00,  5.8996e-01],\n",
       "        [-3.0088e+00, -4.4692e+00, -1.6732e+01, -2.9517e+00,  1.1710e+01,\n",
       "         -1.1393e+01,  7.0091e+00, -8.5887e+00,  3.0432e+00,  1.0512e+00,\n",
       "         -9.8261e+00,  4.0005e+00, -1.9242e+00,  3.0750e+00, -2.3385e+00,\n",
       "          2.9384e+00, -1.1842e+00,  1.8167e+01, -3.3603e-01, -4.5077e+00,\n",
       "         -5.0385e+00, -3.2420e+00,  1.4439e+01, -1.5128e+01, -4.3021e+00,\n",
       "          1.3790e+01,  2.2365e+00],\n",
       "        [-9.6305e+00,  1.4939e+01,  1.2592e+01,  8.6687e+00, -1.5139e+01,\n",
       "          3.2233e+00,  7.3641e+00, -7.0430e+00, -5.1357e+00,  2.2856e-02,\n",
       "          2.0298e+00,  9.3355e+00, -8.6624e-01,  6.0250e+00, -9.1530e+00,\n",
       "          8.2638e-01, -3.4893e-01, -1.7576e-01, -8.5076e+00, -3.7636e+00,\n",
       "         -2.3550e+00,  1.5538e+01,  8.6370e+00,  2.4770e+00, -4.3730e+00,\n",
       "         -7.8310e-01,  3.4189e+00],\n",
       "        [-1.2178e+01,  1.2972e+01,  9.0348e+00,  3.2310e+00, -1.8392e+01,\n",
       "         -1.8115e+00,  5.0787e+00, -1.1237e+01, -3.9280e+00,  5.8872e+00,\n",
       "          9.7454e+00,  8.1385e+00, -2.8959e+00,  5.8286e+00, -7.4056e+00,\n",
       "          3.0329e+00,  1.5797e+00,  5.3701e+00, -9.5129e+00, -2.2212e+00,\n",
       "         -1.8144e+00,  1.9396e+01,  7.6534e+00,  5.8352e+00, -6.5884e+00,\n",
       "          1.8184e+00,  5.4430e+00],\n",
       "        [-8.1173e+00,  5.4696e+00,  1.8115e+00,  5.7834e+00, -5.8651e+00,\n",
       "          7.1387e+00, -1.3547e+00,  4.2279e+00,  6.8546e-01,  1.1137e+00,\n",
       "         -6.7457e+00,  1.3206e+01,  6.1000e+00,  6.1181e+00, -1.0110e+01,\n",
       "          1.0880e+01, -2.3077e+00, -2.9016e+00, -1.3132e+01,  2.7832e+00,\n",
       "          5.6824e+00, -1.3494e+00, -2.6907e+00,  8.4866e+00,  2.5436e+00,\n",
       "         -5.7137e-01,  3.3157e+00],\n",
       "        [-2.0185e+00, -1.9562e+00,  1.4847e+00,  9.6248e+00,  9.9132e+00,\n",
       "          3.4078e+00,  9.6577e+00,  1.4332e+00,  2.2126e+00, -3.9870e+00,\n",
       "         -1.0097e+01,  1.0553e+01,  1.8851e+00, -1.0851e+01, -4.7691e+00,\n",
       "          4.7379e-01,  3.3954e+00, -4.4302e+00,  5.7846e+00,  2.7688e-01,\n",
       "         -4.3160e-01,  1.2514e+01,  5.2727e+00, -4.9839e+00, -4.1979e+00,\n",
       "         -8.1955e+00,  4.0244e+00],\n",
       "        [ 2.8481e+00, -1.5286e+00,  1.1438e+01, -1.5732e-01, -1.7145e+00,\n",
       "         -1.1244e+01,  4.7151e+00, -2.1587e+01, -1.4154e-01,  5.3175e+00,\n",
       "          1.1009e+01,  1.0141e+00, -6.8631e+00,  5.2592e+00,  2.2951e+00,\n",
       "          2.2865e-01, -7.2626e+00,  1.4169e+00,  8.8807e+00, -6.8774e+00,\n",
       "         -4.3087e+00,  2.3670e+00,  4.3044e+00, -1.4972e+01, -6.4225e+00,\n",
       "          2.0471e+01, -5.8511e+00],\n",
       "        [-5.8059e+00, -1.5881e+00,  2.0657e+01,  4.4736e+00, -2.5038e+01,\n",
       "          1.6818e+00, -9.0447e-01, -4.5913e+00, -6.3336e+00,  4.8404e+00,\n",
       "          8.7391e+00,  6.7488e+00, -6.0147e+00,  9.5417e+00, -4.2965e+00,\n",
       "          5.5551e+00, -1.0278e+00, -1.0740e+00, -5.7528e+00, -5.0031e+00,\n",
       "          6.6569e+00, -1.7004e+00,  4.6897e+00, -4.8523e-01, -6.4822e-01,\n",
       "          2.8384e+00, -6.0715e+00],\n",
       "        [-1.3423e+01,  1.0799e+01,  1.5527e+01,  6.9585e+00, -1.6568e+01,\n",
       "          1.0776e-01,  4.9709e+00, -1.1904e+01, -1.4495e+00,  3.8240e+00,\n",
       "          5.4575e+00,  9.4573e+00,  1.8387e+00,  4.9526e+00, -9.9242e+00,\n",
       "          1.2125e+00, -7.9665e-01, -4.7542e+00, -9.0021e+00, -1.0506e+00,\n",
       "          6.9462e-01,  1.3234e+01, -6.1395e+00,  5.3178e+00, -2.3378e+00,\n",
       "          3.4774e+00,  7.3432e+00]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logits.shape, logits.dtype)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3a3214a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e80503ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a23f35f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0000001192092896"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prob.shape)\n",
    "prob[0,:].sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bcb45518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.5864)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "da59bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- now made respectable :) -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "090708c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "# for w in words[:5]:\n",
    "for w in words:\n",
    "    \n",
    "#     print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "#         print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "72ccc6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "683e5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6,100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = (C, W1, b1, W2, b2)\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "85b9331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c454eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.505229949951172\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # forward pass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    XDim0 = X.shape[0]\n",
    "    h = torch.zeros((XDim0, 100))\n",
    "    for i in range(XDim0):\n",
    "        h[i] = torch.tanh(emb.view(-1, 6)[i,:] @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147f303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
